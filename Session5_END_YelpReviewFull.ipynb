{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session5_END_YelpReviewFull.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNys/LuwtXV7G3X1s45UVWk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NLP-END3/Session5/blob/main/Session5_END_YelpReviewFull.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKQt08twMV6R"
      },
      "source": [
        "import torch\n",
        "from torchtext.datasets import IMDB,YelpReviewFull,YahooAnswers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-1jcyGPWFky",
        "outputId": "61f2b764-4d69-4022-df40-b9d123d8fc1e"
      },
      "source": [
        "help(IMDB), help(YelpReviewFull), help(YahooAnswers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function IMDB in module torchtext.datasets.imdb:\n",
            "\n",
            "IMDB(root='.data', split=('train', 'test'))\n",
            "    IMDB dataset\n",
            "    \n",
            "    Separately returns the train/test split\n",
            "    \n",
            "    Number of lines per split:\n",
            "        train: 25000\n",
            "    \n",
            "        test: 25000\n",
            "    \n",
            "    \n",
            "    Number of classes\n",
            "        2\n",
            "    \n",
            "    \n",
            "    Args:\n",
            "        root: Directory where the datasets are saved.\n",
            "            Default: .data\n",
            "        split: split or splits to be returned. Can be a string or tuple of strings.\n",
            "            Default: ('train', 'test')\n",
            "\n",
            "Help on function YelpReviewFull in module torchtext.datasets.yelpreviewfull:\n",
            "\n",
            "YelpReviewFull(root='.data', split=('train', 'test'))\n",
            "    YelpReviewFull dataset\n",
            "    \n",
            "    Separately returns the train/test split\n",
            "    \n",
            "    Number of lines per split:\n",
            "        train: 650000\n",
            "    \n",
            "        test: 50000\n",
            "    \n",
            "    \n",
            "    Number of classes\n",
            "        5\n",
            "    \n",
            "    \n",
            "    Args:\n",
            "        root: Directory where the datasets are saved.\n",
            "            Default: .data\n",
            "        split: split or splits to be returned. Can be a string or tuple of strings.\n",
            "            Default: ('train', 'test')\n",
            "\n",
            "Help on function YahooAnswers in module torchtext.datasets.yahooanswers:\n",
            "\n",
            "YahooAnswers(root='.data', split=('train', 'test'))\n",
            "    YahooAnswers dataset\n",
            "    \n",
            "    Separately returns the train/test split\n",
            "    \n",
            "    Number of lines per split:\n",
            "        train: 1400000\n",
            "    \n",
            "        test: 60000\n",
            "    \n",
            "    \n",
            "    Number of classes\n",
            "        10\n",
            "    \n",
            "    \n",
            "    Args:\n",
            "        root: Directory where the datasets are saved.\n",
            "            Default: .data\n",
            "        split: split or splits to be returned. Can be a string or tuple of strings.\n",
            "            Default: ('train', 'test')\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8NObsdtWFhW",
        "outputId": "2532c9f7-e93e-42bc-f4bd-32b264c53bb1"
      },
      "source": [
        "data_set = input('What is your choice of dataset? : IMDB, YelpReviewFull, YahooAnswers')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is your choice of dataset? : IMDB, YelpReviewFull, YahooAnswersYelpReviewFull\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQZDMRjC1wXX",
        "outputId": "287f36a2-8f4e-49a6-bc20-2257a7532a1d"
      },
      "source": [
        "print(f'Chosen dataset : {data_set}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen dataset : YelpReviewFull\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2RLbRfA1wPH"
      },
      "source": [
        "#train_iter_IMDB = IMDB(split = 'train')\n",
        "train_iter_YelpReviewFull = YelpReviewFull(split = 'train')\n",
        "#train_iter_YahooAnswers = YahooAnswers(split = 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwdoGkm9895a"
      },
      "source": [
        "## Selecting the right dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHdfeoT288Cr"
      },
      "source": [
        "#data_sets = {'IMDB':train_iter_IMDB, 'YelpReviewFull': train_iter_YelpReviewFull} #, 'YahooAnswers': train_iter_YahooAnswers}\n",
        "train_iter = YelpReviewFull(split='train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGmfIgbL5mTv"
      },
      "source": [
        "## Exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKP0VA6U5lYh",
        "outputId": "f41001a5-296f-4251-c134-cce318e62724"
      },
      "source": [
        "len(train_iter), type(train_iter), next(iter(train_iter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(650000,\n",
              " torchtext.data.datasets_utils._RawTextIterableDataset,\n",
              " (5,\n",
              "  \"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\"))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le_7zVMp76G4"
      },
      "source": [
        "## NUmber of positive and Negative examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5zm98Vg75HB",
        "outputId": "9454b251-54e7-468b-9c3f-f00f5fd8febf"
      },
      "source": [
        "train_iter = YelpReviewFull(split='train')\n",
        "\n",
        "for (line_number, (label,text)) in enumerate(train_iter):\n",
        "  if line_number < 5:\n",
        "    print(label, text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\n",
            "2 Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\n",
            "4 Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\n",
            "4 Got a letter in the mail last week that said Dr. Goldberg is moving to Arizona to take a new position there in June.  He will be missed very much.  \\n\\nI think finding a new doctor in NYC that you actually like might almost be as awful as trying to find a date!\n",
            "1 I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOy0IDfRjgOD"
      },
      "source": [
        "## Tokenization & Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppsy0DuL_7-S"
      },
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba7SiWx4_77D"
      },
      "source": [
        "tokenizer = get_tokenizer('basic_english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktFKfHyX_74R",
        "outputId": "097a04d7-5fe8-46ae-c7e4-ee96b944eba0"
      },
      "source": [
        "tokenizer(\"I am an Indian since 1990\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'an', 'indian', 'since', '1990']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjeGJAVhj9Zm"
      },
      "source": [
        "train_iter = YelpReviewFull(split = 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PFSEdDOj9Un",
        "outputId": "e093f56a-2ceb-4ed0-8a4a-ee379af738b1"
      },
      "source": [
        "len(train_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "650000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_ddsp-wj9Je"
      },
      "source": [
        "def yield_tokens(data_iter):\n",
        "  for _,text in data_iter:\n",
        "    yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter),specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfv5wV8Im16U",
        "outputId": "275ccf69-ad39-4118-b91b-854e59ac8a31"
      },
      "source": [
        "len(vocab) # vocab size is 519819"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "519819"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9_eDb1AlC43"
      },
      "source": [
        "## Text and Label Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQrUmzFyk3SH"
      },
      "source": [
        "text_pipeline = lambda x : vocab(tokenizer(x))\n",
        "label_pipeline = lambda x : int(x) - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esP154mhk3Op",
        "outputId": "748aa689-719d-43a9-e9f0-072981fcc9bf"
      },
      "source": [
        "text_pipeline(\"the movie is great\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1058, 14, 58]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPy6R4VPk3Lr",
        "outputId": "04f0f959-d5f7-4393-fa92-f9571b0da675"
      },
      "source": [
        "label_pipeline(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VpswA06nvUw"
      },
      "source": [
        "## Collate_fn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbVYb7ywk3Id"
      },
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHn1hW8dny6_"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_iter = YelpReviewFull(split='train')\n",
        "dataloader = DataLoader(train_iter, batch_size = 8, shuffle = False, collate_fn = collate_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CPmemP9ocsx"
      },
      "source": [
        "## Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWRRP9f1ny3c"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "523S_6Buny0V",
        "outputId": "dd348ece-88c0-49be-fdc1-5c66cfb9f2b9"
      },
      "source": [
        "train_iter = YelpReviewFull(split='train')\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n",
        "print(f'Vocabulary Size : {vocab_size}')\n",
        "print(f'Embedding Size : {emsize}')\n",
        "print(f'Number of Classes : {num_class}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size : 519819\n",
            "Embedding Size : 64\n",
            "Number of Classes : 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5v1r8mZnyxN"
      },
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predited_label = model(text, offsets)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1) # disuccees\n",
        "        optimizer.step()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqSrcrU9pvtP"
      },
      "source": [
        "## Running the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1IEw4hok3E0",
        "outputId": "d6c9f4e9-c59e-4610-e57a-cd0461e23ec7"
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64 # batch size for training\n",
        "  \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter, test_iter = YelpReviewFull()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = \\\n",
        "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
        "\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 9649 batches | accuracy    0.390\n",
            "| epoch   1 |  1000/ 9649 batches | accuracy    0.488\n",
            "| epoch   1 |  1500/ 9649 batches | accuracy    0.509\n",
            "| epoch   1 |  2000/ 9649 batches | accuracy    0.530\n",
            "| epoch   1 |  2500/ 9649 batches | accuracy    0.540\n",
            "| epoch   1 |  3000/ 9649 batches | accuracy    0.541\n",
            "| epoch   1 |  3500/ 9649 batches | accuracy    0.549\n",
            "| epoch   1 |  4000/ 9649 batches | accuracy    0.551\n",
            "| epoch   1 |  4500/ 9649 batches | accuracy    0.554\n",
            "| epoch   1 |  5000/ 9649 batches | accuracy    0.558\n",
            "| epoch   1 |  5500/ 9649 batches | accuracy    0.558\n",
            "| epoch   1 |  6000/ 9649 batches | accuracy    0.562\n",
            "| epoch   1 |  6500/ 9649 batches | accuracy    0.562\n",
            "| epoch   1 |  7000/ 9649 batches | accuracy    0.561\n",
            "| epoch   1 |  7500/ 9649 batches | accuracy    0.563\n",
            "| epoch   1 |  8000/ 9649 batches | accuracy    0.565\n",
            "| epoch   1 |  8500/ 9649 batches | accuracy    0.566\n",
            "| epoch   1 |  9000/ 9649 batches | accuracy    0.566\n",
            "| epoch   1 |  9500/ 9649 batches | accuracy    0.575\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 224.48s | valid accuracy    0.577 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 9649 batches | accuracy    0.574\n",
            "| epoch   2 |  1000/ 9649 batches | accuracy    0.580\n",
            "| epoch   2 |  1500/ 9649 batches | accuracy    0.574\n",
            "| epoch   2 |  2000/ 9649 batches | accuracy    0.568\n",
            "| epoch   2 |  2500/ 9649 batches | accuracy    0.577\n",
            "| epoch   2 |  3000/ 9649 batches | accuracy    0.577\n",
            "| epoch   2 |  3500/ 9649 batches | accuracy    0.579\n",
            "| epoch   2 |  4000/ 9649 batches | accuracy    0.576\n",
            "| epoch   2 |  4500/ 9649 batches | accuracy    0.577\n",
            "| epoch   2 |  5000/ 9649 batches | accuracy    0.582\n",
            "| epoch   2 |  5500/ 9649 batches | accuracy    0.577\n",
            "| epoch   2 |  6000/ 9649 batches | accuracy    0.571\n",
            "| epoch   2 |  6500/ 9649 batches | accuracy    0.581\n",
            "| epoch   2 |  7000/ 9649 batches | accuracy    0.584\n",
            "| epoch   2 |  7500/ 9649 batches | accuracy    0.577\n",
            "| epoch   2 |  8000/ 9649 batches | accuracy    0.579\n",
            "| epoch   2 |  8500/ 9649 batches | accuracy    0.574\n",
            "| epoch   2 |  9000/ 9649 batches | accuracy    0.576\n",
            "| epoch   2 |  9500/ 9649 batches | accuracy    0.580\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 214.34s | valid accuracy    0.573 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 9649 batches | accuracy    0.596\n",
            "| epoch   3 |  1000/ 9649 batches | accuracy    0.601\n",
            "| epoch   3 |  1500/ 9649 batches | accuracy    0.605\n",
            "| epoch   3 |  2000/ 9649 batches | accuracy    0.600\n",
            "| epoch   3 |  2500/ 9649 batches | accuracy    0.600\n",
            "| epoch   3 |  3000/ 9649 batches | accuracy    0.604\n",
            "| epoch   3 |  3500/ 9649 batches | accuracy    0.603\n",
            "| epoch   3 |  4000/ 9649 batches | accuracy    0.601\n",
            "| epoch   3 |  4500/ 9649 batches | accuracy    0.601\n",
            "| epoch   3 |  5000/ 9649 batches | accuracy    0.606\n",
            "| epoch   3 |  5500/ 9649 batches | accuracy    0.599\n",
            "| epoch   3 |  6000/ 9649 batches | accuracy    0.599\n",
            "| epoch   3 |  6500/ 9649 batches | accuracy    0.600\n",
            "| epoch   3 |  7000/ 9649 batches | accuracy    0.601\n",
            "| epoch   3 |  7500/ 9649 batches | accuracy    0.598\n",
            "| epoch   3 |  8000/ 9649 batches | accuracy    0.598\n",
            "| epoch   3 |  8500/ 9649 batches | accuracy    0.602\n",
            "| epoch   3 |  9000/ 9649 batches | accuracy    0.600\n",
            "| epoch   3 |  9500/ 9649 batches | accuracy    0.605\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 209.08s | valid accuracy    0.591 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 9649 batches | accuracy    0.601\n",
            "| epoch   4 |  1000/ 9649 batches | accuracy    0.601\n",
            "| epoch   4 |  1500/ 9649 batches | accuracy    0.603\n",
            "| epoch   4 |  2000/ 9649 batches | accuracy    0.609\n",
            "| epoch   4 |  2500/ 9649 batches | accuracy    0.599\n",
            "| epoch   4 |  3000/ 9649 batches | accuracy    0.599\n",
            "| epoch   4 |  3500/ 9649 batches | accuracy    0.599\n",
            "| epoch   4 |  4000/ 9649 batches | accuracy    0.603\n",
            "| epoch   4 |  4500/ 9649 batches | accuracy    0.602\n",
            "| epoch   4 |  5000/ 9649 batches | accuracy    0.603\n",
            "| epoch   4 |  5500/ 9649 batches | accuracy    0.605\n",
            "| epoch   4 |  6000/ 9649 batches | accuracy    0.608\n",
            "| epoch   4 |  6500/ 9649 batches | accuracy    0.598\n",
            "| epoch   4 |  7000/ 9649 batches | accuracy    0.607\n",
            "| epoch   4 |  7500/ 9649 batches | accuracy    0.600\n",
            "| epoch   4 |  8000/ 9649 batches | accuracy    0.599\n",
            "| epoch   4 |  8500/ 9649 batches | accuracy    0.610\n",
            "| epoch   4 |  9000/ 9649 batches | accuracy    0.604\n",
            "| epoch   4 |  9500/ 9649 batches | accuracy    0.601\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 215.42s | valid accuracy    0.592 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 9649 batches | accuracy    0.600\n",
            "| epoch   5 |  1000/ 9649 batches | accuracy    0.601\n",
            "| epoch   5 |  1500/ 9649 batches | accuracy    0.601\n",
            "| epoch   5 |  2000/ 9649 batches | accuracy    0.608\n",
            "| epoch   5 |  2500/ 9649 batches | accuracy    0.602\n",
            "| epoch   5 |  3000/ 9649 batches | accuracy    0.601\n",
            "| epoch   5 |  3500/ 9649 batches | accuracy    0.602\n",
            "| epoch   5 |  4000/ 9649 batches | accuracy    0.602\n",
            "| epoch   5 |  4500/ 9649 batches | accuracy    0.600\n",
            "| epoch   5 |  5000/ 9649 batches | accuracy    0.607\n",
            "| epoch   5 |  5500/ 9649 batches | accuracy    0.604\n",
            "| epoch   5 |  6000/ 9649 batches | accuracy    0.605\n",
            "| epoch   5 |  6500/ 9649 batches | accuracy    0.603\n",
            "| epoch   5 |  7000/ 9649 batches | accuracy    0.602\n",
            "| epoch   5 |  7500/ 9649 batches | accuracy    0.602\n",
            "| epoch   5 |  8000/ 9649 batches | accuracy    0.610\n",
            "| epoch   5 |  8500/ 9649 batches | accuracy    0.606\n",
            "| epoch   5 |  9000/ 9649 batches | accuracy    0.610\n",
            "| epoch   5 |  9500/ 9649 batches | accuracy    0.604\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 247.37s | valid accuracy    0.591 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 9649 batches | accuracy    0.604\n",
            "| epoch   6 |  1000/ 9649 batches | accuracy    0.610\n",
            "| epoch   6 |  1500/ 9649 batches | accuracy    0.607\n",
            "| epoch   6 |  2000/ 9649 batches | accuracy    0.603\n",
            "| epoch   6 |  2500/ 9649 batches | accuracy    0.609\n",
            "| epoch   6 |  3000/ 9649 batches | accuracy    0.603\n",
            "| epoch   6 |  3500/ 9649 batches | accuracy    0.608\n",
            "| epoch   6 |  4000/ 9649 batches | accuracy    0.605\n",
            "| epoch   6 |  4500/ 9649 batches | accuracy    0.605\n",
            "| epoch   6 |  5000/ 9649 batches | accuracy    0.602\n",
            "| epoch   6 |  5500/ 9649 batches | accuracy    0.606\n",
            "| epoch   6 |  6000/ 9649 batches | accuracy    0.607\n",
            "| epoch   6 |  6500/ 9649 batches | accuracy    0.606\n",
            "| epoch   6 |  7000/ 9649 batches | accuracy    0.612\n",
            "| epoch   6 |  7500/ 9649 batches | accuracy    0.604\n",
            "| epoch   6 |  8000/ 9649 batches | accuracy    0.609\n",
            "| epoch   6 |  8500/ 9649 batches | accuracy    0.604\n",
            "| epoch   6 |  9000/ 9649 batches | accuracy    0.604\n",
            "| epoch   6 |  9500/ 9649 batches | accuracy    0.605\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 236.82s | valid accuracy    0.595 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 9649 batches | accuracy    0.606\n",
            "| epoch   7 |  1000/ 9649 batches | accuracy    0.602\n",
            "| epoch   7 |  1500/ 9649 batches | accuracy    0.605\n",
            "| epoch   7 |  2000/ 9649 batches | accuracy    0.611\n",
            "| epoch   7 |  2500/ 9649 batches | accuracy    0.605\n",
            "| epoch   7 |  3000/ 9649 batches | accuracy    0.610\n",
            "| epoch   7 |  3500/ 9649 batches | accuracy    0.604\n",
            "| epoch   7 |  4000/ 9649 batches | accuracy    0.604\n",
            "| epoch   7 |  4500/ 9649 batches | accuracy    0.607\n",
            "| epoch   7 |  5000/ 9649 batches | accuracy    0.605\n",
            "| epoch   7 |  5500/ 9649 batches | accuracy    0.606\n",
            "| epoch   7 |  6000/ 9649 batches | accuracy    0.608\n",
            "| epoch   7 |  6500/ 9649 batches | accuracy    0.606\n",
            "| epoch   7 |  7000/ 9649 batches | accuracy    0.609\n",
            "| epoch   7 |  7500/ 9649 batches | accuracy    0.609\n",
            "| epoch   7 |  8000/ 9649 batches | accuracy    0.604\n",
            "| epoch   7 |  8500/ 9649 batches | accuracy    0.604\n",
            "| epoch   7 |  9000/ 9649 batches | accuracy    0.609\n",
            "| epoch   7 |  9500/ 9649 batches | accuracy    0.608\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 230.47s | valid accuracy    0.595 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 9649 batches | accuracy    0.604\n",
            "| epoch   8 |  1000/ 9649 batches | accuracy    0.606\n",
            "| epoch   8 |  1500/ 9649 batches | accuracy    0.611\n",
            "| epoch   8 |  2000/ 9649 batches | accuracy    0.605\n",
            "| epoch   8 |  2500/ 9649 batches | accuracy    0.608\n",
            "| epoch   8 |  3000/ 9649 batches | accuracy    0.604\n",
            "| epoch   8 |  3500/ 9649 batches | accuracy    0.605\n",
            "| epoch   8 |  4000/ 9649 batches | accuracy    0.607\n",
            "| epoch   8 |  4500/ 9649 batches | accuracy    0.609\n",
            "| epoch   8 |  5000/ 9649 batches | accuracy    0.609\n",
            "| epoch   8 |  5500/ 9649 batches | accuracy    0.604\n",
            "| epoch   8 |  6000/ 9649 batches | accuracy    0.605\n",
            "| epoch   8 |  6500/ 9649 batches | accuracy    0.605\n",
            "| epoch   8 |  7000/ 9649 batches | accuracy    0.607\n",
            "| epoch   8 |  7500/ 9649 batches | accuracy    0.608\n",
            "| epoch   8 |  8000/ 9649 batches | accuracy    0.600\n",
            "| epoch   8 |  8500/ 9649 batches | accuracy    0.609\n",
            "| epoch   8 |  9000/ 9649 batches | accuracy    0.608\n",
            "| epoch   8 |  9500/ 9649 batches | accuracy    0.606\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 243.23s | valid accuracy    0.594 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 9649 batches | accuracy    0.612\n",
            "| epoch   9 |  1000/ 9649 batches | accuracy    0.604\n",
            "| epoch   9 |  1500/ 9649 batches | accuracy    0.608\n",
            "| epoch   9 |  2000/ 9649 batches | accuracy    0.607\n",
            "| epoch   9 |  2500/ 9649 batches | accuracy    0.603\n",
            "| epoch   9 |  3000/ 9649 batches | accuracy    0.606\n",
            "| epoch   9 |  3500/ 9649 batches | accuracy    0.602\n",
            "| epoch   9 |  4000/ 9649 batches | accuracy    0.609\n",
            "| epoch   9 |  4500/ 9649 batches | accuracy    0.608\n",
            "| epoch   9 |  5000/ 9649 batches | accuracy    0.607\n",
            "| epoch   9 |  5500/ 9649 batches | accuracy    0.608\n",
            "| epoch   9 |  6000/ 9649 batches | accuracy    0.603\n",
            "| epoch   9 |  6500/ 9649 batches | accuracy    0.605\n",
            "| epoch   9 |  7000/ 9649 batches | accuracy    0.612\n",
            "| epoch   9 |  7500/ 9649 batches | accuracy    0.606\n",
            "| epoch   9 |  8000/ 9649 batches | accuracy    0.607\n",
            "| epoch   9 |  8500/ 9649 batches | accuracy    0.607\n",
            "| epoch   9 |  9000/ 9649 batches | accuracy    0.607\n",
            "| epoch   9 |  9500/ 9649 batches | accuracy    0.605\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 234.38s | valid accuracy    0.595 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 9649 batches | accuracy    0.610\n",
            "| epoch  10 |  1000/ 9649 batches | accuracy    0.606\n",
            "| epoch  10 |  1500/ 9649 batches | accuracy    0.603\n",
            "| epoch  10 |  2000/ 9649 batches | accuracy    0.607\n",
            "| epoch  10 |  2500/ 9649 batches | accuracy    0.609\n",
            "| epoch  10 |  3000/ 9649 batches | accuracy    0.608\n",
            "| epoch  10 |  3500/ 9649 batches | accuracy    0.604\n",
            "| epoch  10 |  4000/ 9649 batches | accuracy    0.607\n",
            "| epoch  10 |  4500/ 9649 batches | accuracy    0.610\n",
            "| epoch  10 |  5000/ 9649 batches | accuracy    0.607\n",
            "| epoch  10 |  5500/ 9649 batches | accuracy    0.607\n",
            "| epoch  10 |  6000/ 9649 batches | accuracy    0.606\n",
            "| epoch  10 |  6500/ 9649 batches | accuracy    0.606\n",
            "| epoch  10 |  7000/ 9649 batches | accuracy    0.607\n",
            "| epoch  10 |  7500/ 9649 batches | accuracy    0.605\n",
            "| epoch  10 |  8000/ 9649 batches | accuracy    0.606\n",
            "| epoch  10 |  8500/ 9649 batches | accuracy    0.604\n",
            "| epoch  10 |  9000/ 9649 batches | accuracy    0.603\n",
            "| epoch  10 |  9500/ 9649 batches | accuracy    0.604\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time: 216.45s | valid accuracy    0.595 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fzDlerdp_8Y"
      },
      "source": [
        "## Testing Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GaPcAmNp_lS",
        "outputId": "5a3689fa-45fd-4b3a-e51a-6f6f7f19add0"
      },
      "source": [
        "print('Checking the results of test dataset.')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print('test accuracy {:8.3f}'.format(accu_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    0.596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZwTyEW5p_ig"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}